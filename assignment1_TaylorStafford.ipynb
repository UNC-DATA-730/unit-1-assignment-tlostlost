{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e757ec2c-1a9a-49c7-928d-ae3e7eb9cefb",
   "metadata": {},
   "source": [
    "## Assignment #1 DATA 730\n",
    "#### Taylor Stafford"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12882e8c-a45f-45ee-b13b-368f0099c67e",
   "metadata": {},
   "source": [
    "This assignment tests that you have the course tech stack set up. If you do, you will be able to complete this notebook and turn-in your work by pushing to your assignment repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e522b4-c275-4043-a37f-f2e49eb243bd",
   "metadata": {},
   "source": [
    "## Tech stack checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31feed-577b-4c7d-a409-6429cad04cfd",
   "metadata": {},
   "source": [
    "*Fill out the checklist below once you have completed each task:*\n",
    "\n",
    "- [x] GitHub account \n",
    "- [x] SageMaker Studio Lab account "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02701813-a27b-45f9-a48b-9cfe343eac65",
   "metadata": {},
   "source": [
    "**Create the `data730` conda environment by right clicking the `environment.yml` file from the repo in SageMaker Studio Lab and selecting `Build conda Environment`.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158255df-7b9f-4cf4-b644-632172a5152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li><span style=white-space:pre-wrap>'data730               *  /home/studio-lab-user/.conda/envs/data730'</span></li><li><span style=white-space:pre-wrap>'data730-lecture          /home/studio-lab-user/.conda/envs/data730-lecture'</span></li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'data730               *  /home/studio-lab-user/.conda/envs/data730'\n",
       "\\item 'data730-lecture          /home/studio-lab-user/.conda/envs/data730-lecture'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. <span style=white-space:pre-wrap>'data730               *  /home/studio-lab-user/.conda/envs/data730'</span>\n",
       "2. <span style=white-space:pre-wrap>'data730-lecture          /home/studio-lab-user/.conda/envs/data730-lecture'</span>\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"data730               *  /home/studio-lab-user/.conda/envs/data730\"        \n",
       "[2] \"data730-lecture          /home/studio-lab-user/.conda/envs/data730-lecture\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uncomment the following line and execute this cell to demonstrate you have created the data730 conda environment\n",
    "system('conda env list | grep data730', intern = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc383334-802a-45bf-bc7e-150fdb963bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Your system is mis-configured: ‘/var/db/timezone/localtime’ is not a symlink”\n",
      "Warning message:\n",
      "“‘/var/db/timezone/localtime’ is not identical to any known timezone file”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.4.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.9     \u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.4.2     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr       \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mtailor      \u001b[39m 0.1.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2     \u001b[39m 3.5.2     \u001b[32m✔\u001b[39m \u001b[34mtidyr       \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.9     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 2.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.5.1     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.3.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.3.3     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.1.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr       \u001b[39m 1.1.0     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.3.2\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mpurrr\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mscales\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m  masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m     masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m  masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uncomment the following line and execute this cell to demonstrate that you have installed the tidymodels package\n",
    "library('tidymodels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6235a95-e0a6-4f7a-865a-b1d891796125",
   "metadata": {},
   "source": [
    "## Let's do some statistical inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc5e612-a5b6-4a90-90fb-989fcce40874",
   "metadata": {},
   "source": [
    "Read [this article](https://www.theguardian.com/world/2002/jan/04/euro.eu2). \n",
    "\n",
    "Execute the code below to investigate whether the coin is fair..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e16445-2854-49fe-8c5c-0dfd32e0a9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions simulate tossing a fair coin n_tosses number of times for n_iterations number of iterations\n",
    "\n",
    "toss_fair_coin_n_times = function(n_tosses = 250) {\n",
    "    result = ifelse(runif(n = n_tosses) < 0.5, 'heads', 'tails')\n",
    "    result\n",
    "}\n",
    "\n",
    "repeat_the_experiment = function(n_iterations, n_tosses = 250) {\n",
    "    n_heads_each_iteration = c()\n",
    "    for (i in 1:n_iterations) {\n",
    "        n_heads = sum(toss_fair_coin_n_times(n_tosses) == 'heads')\n",
    "        n_heads_each_iteration = c(n_heads_each_iteration, n_heads)\n",
    "    } \n",
    "    n_heads_each_iteration\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0333b3d-7cc6-4fa0-813e-f2d4c863be23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'With a fair coin we would expect a deviation as large or larger than what we observed 9.37% of times'"
      ],
      "text/latex": [
       "'With a fair coin we would expect a deviation as large or larger than what we observed 9.37\\% of times'"
      ],
      "text/markdown": [
       "'With a fair coin we would expect a deviation as large or larger than what we observed 9.37% of times'"
      ],
      "text/plain": [
       "[1] \"With a fair coin we would expect a deviation as large or larger than what we observed 9.37% of times\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's do 10,000 experiments of 250 tosses and see how often our outcome deviates from what was actually observed (139 heads)\n",
    "\n",
    "n_iterations = 10000\n",
    "n_tosses = 250\n",
    "observed_deviation = 139 - 125 # 139 heads observed, expected value for a fair coin of 125\n",
    "\n",
    "n_heads_each_experiment = repeat_the_experiment(n_iterations, n_tosses)\n",
    "\n",
    "x = mean(abs(n_heads_each_experiment - 125) >= observed_deviation)\n",
    "paste0('With a fair coin we would expect a deviation as large or larger than what we observed ', x*100, '% of times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71651-a940-455b-8d30-14660b1aade4",
   "metadata": {},
   "source": [
    "**Do you think the coin was fair?** (Answer below in a markdown cell.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fedabe-f675-494a-8044-e9e1020fe96f",
   "metadata": {},
   "source": [
    "Most coins will have a nearly 50/50 chance on landing on head or tails. These Belgium coins on the other hand appear to land on heads more then tails. In the previous code that runs a test of these coins 10,000 times with 250 tosses we find that the devation between heads and tails is 9.37% that is a large difference from the expected 50/50 chance. Thats nearly, if we generously round up, a 10% chance that the coin will land on heads. This in my opinion means the coins are not fair. I would expect a normal devation to best a very small percentage and this 9.37% is far more then I would want from a fair coin. I think that thesse coins should avoided for fair toss ups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed12a3-5af2-4bcf-b6fe-d662fe8e0c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data730:R",
   "language": "R",
   "name": "conda-env-data730-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
